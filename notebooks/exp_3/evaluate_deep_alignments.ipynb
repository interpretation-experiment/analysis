{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluate 100 alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "N_TEST = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Setup the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: spreadr_exp_3\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.insert(1, os.path.abspath('../..'))\n",
    "import analysis\n",
    "\n",
    "FIG = os.path.join(os.path.abspath(os.path.curdir), '{}.png')\n",
    "DB_NAME = 'spreadr_' + os.path.split(os.path.abspath(os.path.curdir))[1]\n",
    "analysis.setup(DB_NAME)\n",
    "print('Database:', DB_NAME)\n",
    "\n",
    "HAND_ALIGNMENTS_FILE = '../../data/alignments/' + DB_NAME + '/sebastien-lerique.csv'\n",
    "CODINGS_ALIGNMENTS_FILE = ('../../data/codings/'\n",
    "                           + DB_NAME\n",
    "                           + '/alignments'\n",
    "                           + '/sebastien-lerique_on_sebastien-lerique-deep-alignments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Imports for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "from gists.models import Sentence\n",
    "\n",
    "from analysis.transformations import format_deep_alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2 Look at 100 non-trivial deep alignments to code their quality\n",
    "\n",
    "Only look at sentences that have a non-null ordered word distance, to make sure there is change to align on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_sentences(sentence_ids, n):\n",
    "    found = []\n",
    "    while len(found) < n:\n",
    "        sentence_id = sentence_ids.pop()\n",
    "        sentence = Sentence.objects.get(id=sentence_id)\n",
    "        if sentence.parent.ow_distance(sentence) == 0:\n",
    "            # Skip this sentence, it has no interesting transformations\n",
    "            continue\n",
    "        found.append(sentence_id)\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hand_aligned_ids = []\n",
    "with open(HAND_ALIGNMENTS_FILE, 'r') as hand_alignments_file:\n",
    "    reader = csv.DictReader(hand_alignments_file)\n",
    "    for row in reader:\n",
    "        hand_aligned_ids.append(row['sentence_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2646,\n",
       " 1636,\n",
       " 3415,\n",
       " 359,\n",
       " 464,\n",
       " 430,\n",
       " 2179,\n",
       " 2965,\n",
       " 660,\n",
       " 411,\n",
       " 356,\n",
       " 86,\n",
       " 2155,\n",
       " 516,\n",
       " 1961,\n",
       " 456,\n",
       " 3049,\n",
       " 655,\n",
       " 2680,\n",
       " 1147,\n",
       " 931,\n",
       " 2310,\n",
       " 1693,\n",
       " 886,\n",
       " 2380,\n",
       " 937,\n",
       " 2402,\n",
       " 840,\n",
       " 3034,\n",
       " 1330,\n",
       " 3340,\n",
       " 1569,\n",
       " 2647,\n",
       " 2187,\n",
       " 144,\n",
       " 1340,\n",
       " 2069,\n",
       " 1266,\n",
       " 2579,\n",
       " 1372,\n",
       " 3273,\n",
       " 2664,\n",
       " 2196,\n",
       " 794,\n",
       " 2630,\n",
       " 475,\n",
       " 2807,\n",
       " 1337,\n",
       " 1966,\n",
       " 2095,\n",
       " 1246,\n",
       " 2189,\n",
       " 3977,\n",
       " 1849,\n",
       " 1177,\n",
       " 322,\n",
       " 267,\n",
       " 227,\n",
       " 2153,\n",
       " 2577,\n",
       " 2581,\n",
       " 3341,\n",
       " 1582,\n",
       " 256,\n",
       " 3371,\n",
       " 567,\n",
       " 2700,\n",
       " 204,\n",
       " 2363,\n",
       " 1748,\n",
       " 101,\n",
       " 980,\n",
       " 2679,\n",
       " 2765,\n",
       " 2278,\n",
       " 65,\n",
       " 3480,\n",
       " 583,\n",
       " 3625,\n",
       " 3197,\n",
       " 859,\n",
       " 2504,\n",
       " 3099,\n",
       " 514,\n",
       " 1233,\n",
       " 915,\n",
       " 1493,\n",
       " 3683,\n",
       " 3298,\n",
       " 722,\n",
       " 1352,\n",
       " 2199,\n",
       " 3651,\n",
       " 521,\n",
       " 2109,\n",
       " 3923,\n",
       " 304,\n",
       " 670,\n",
       " 335,\n",
       " 3110]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept_sentence_ids = list(Sentence.objects.kept\n",
    "                         .filter(parent__isnull=False)\n",
    "                         .values_list('id', flat=True))\n",
    "testable_sentence_ids = list(set(kept_sentence_ids).difference(hand_aligned_ids))\n",
    "random.shuffle(testable_sentence_ids)\n",
    "\n",
    "found_sentences = find_sentences(testable_sentence_ids, N_TEST)\n",
    "found_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3 Hand-code the alignments for number of errors\n",
    "\n",
    "This is done by hand, and the result is in `CODINGS_ALIGNMENTS_FILE`.\n",
    "\n",
    "I coded alignments with the number of words that we would have to change to get an optimal alignment. Note that for words split into two or merged, no errors were counted if it was coded as all insertions+deletions, or if the main meaning bearers were matched.\n",
    "\n",
    "The feeling is that, often, errors are words at the margin of bigger changes, and the overall operation by the subject is nonetheless well captured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4 Counting the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_errors = []\n",
    "with open(CODINGS_ALIGNMENTS_FILE, 'r') as codings_file:\n",
    "    reader = csv.DictReader(codings_file)\n",
    "    for row in reader:\n",
    "        n_errors.append(row['n_errors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 sentences have 0 error(s)\n",
      "12 sentences have 1 error(s)\n",
      "4 sentences have 2 error(s)\n",
      "1 sentences have 4 error(s)\n",
      "1 sentences have 6 error(s)\n",
      "2 sentences have 3 error(s)\n",
      "1 sentences have 5 error(s)\n"
     ]
    }
   ],
   "source": [
    "for (error_count, count) in Counter(n_errors).items():\\\n",
    "    print('{} sentences have {} error(s)'.format(count, error_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
